###############################################################
# app.py â€” ETF SMA ç­–ç•¥æˆ°æƒ…å®¤ (é€šç”¨ç‰ˆ - Bugä¿®å¾©)
###############################################################

import streamlit as st
import yfinance as yf
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime, timedelta

# 1. é é¢è¨­å®š
st.set_page_config(
    page_title="ETF SMA æˆ°æƒ…å®¤ (é€šç”¨ç‰ˆ)",
    layout="wide",
)

# ===============================================================
# å…¨åŸŸè¨­å®šï¼šETF å°ç…§è¡¨
# ===============================================================
ETF_MAPPING = {
    "ğŸ‡¹ğŸ‡¼ å°è‚¡ - 0050 (å…ƒå¤§å°ç£50)": {
        "symbol": "0050.TW",
        "leverage_options": {
            "00631L (å…ƒå¤§å°ç£50æ­£2)": "00631L.TW",
            "00663L (åœ‹æ³°è‡ºç£åŠ æ¬Šæ­£2)": "00663L.TW"
        }
    },
    "ğŸ‡ºğŸ‡¸ ç¾è‚¡ - QQQ (ç´æ–¯é”å…‹100)": {
        "symbol": "QQQ",
        "leverage_options": {
            "QLD (ProShares å…©å€åšå¤š)": "QLD",
            "TQQQ (ProShares ä¸‰å€åšå¤š)": "TQQQ"
        }
    },
    "ğŸ‡ºğŸ‡¸ ç¾è‚¡ - SPY (æ¨™æ™®500)": {
        "symbol": "SPY",
        "leverage_options": {
            "SSO (ProShares å…©å€åšå¤š)": "SSO",
            "UPRO (ProShares ä¸‰å€åšå¤š)": "UPRO"
        }
    },
    "ğŸ‡ºğŸ‡¸ ç¾è‚¡ - VTI (æ•´é«”è‚¡å¸‚)": {
        "symbol": "VTI",
        "leverage_options": {
            "SSO (å› ç„¡VTIæ­£2ï¼Œæš«ç”¨SPYæ­£2ä»£æ›¿)": "SSO" 
        }
    }
}

with st.sidebar:
    st.markdown("### ğŸ”— å¿«é€Ÿé€£çµ")
    st.page_link("https://hamr-lab.com/", label="å›åˆ°å®˜ç¶²é¦–é ", icon="ğŸ ")
    st.page_link("https://www.youtube.com/@hamr-lab", label="YouTube é »é“", icon="ğŸ“º")
    st.divider()

st.title("ğŸ“Š åŸå‹ vs æ§“æ¡¿ ETF â€” SMA æ·±åº¦é‡åŒ–åˆ†æ")

# ===============================================================
# å€å¡Š 1: æ¨™çš„é¸æ“‡èˆ‡å€é–“åµæ¸¬
# ===============================================================

sel_col1, sel_col2 = st.columns(2)

with sel_col1:
    proto_keys = list(ETF_MAPPING.keys())
    selected_proto_name = st.selectbox("åŸå‹ ETF (è¨Šè™Ÿä¾†æº)", proto_keys)
    proto_symbol = ETF_MAPPING[selected_proto_name]["symbol"]

with sel_col2:
    lev_options = ETF_MAPPING[selected_proto_name]["leverage_options"]
    selected_lev_name = st.selectbox("æ§“æ¡¿ ETF (å¯¦éš›é€²å‡ºå ´æ¨™çš„)", list(lev_options.keys()))
    lev_symbol = lev_options[selected_lev_name]

# ---------------------------------------------------------------
# è‡ªå‹•åµæ¸¬å¯å›æ¸¬å€é–“ (Metadata Fetch)
# ---------------------------------------------------------------
@st.cache_data(ttl=3600)
def get_common_date_range(sym1, sym2):
    try:
        df1 = yf.download(sym1, period="max", progress=False, auto_adjust=False)
        df2 = yf.download(sym2, period="max", progress=False, auto_adjust=False)
        
        if df1.empty or df2.empty:
            return None, None
            
        if isinstance(df1.columns, pd.MultiIndex): df1 = df1.xs("Close", axis=1, level=0, drop_level=True)
        if isinstance(df2.columns, pd.MultiIndex): df2 = df2.xs("Close", axis=1, level=0, drop_level=True)
        
        start1 = df1.index.min().date()
        start2 = df2.index.min().date()
        end1 = df1.index.max().date()
        end2 = df2.index.max().date()
        
        common_start = max(start1, start2)
        common_end = min(end1, end2)
        
        return common_start, common_end
    except Exception as e:
        return None, None

with st.spinner("æ­£åœ¨åµæ¸¬å¯å›æ¸¬å€é–“..."):
    min_date, max_date = get_common_date_range(proto_symbol, lev_symbol)

if min_date and max_date:
    st.info(f"ğŸ“Œ **å¯å›æ¸¬å€é–“** ï¼š {min_date} ~ {max_date}")
    st.session_state['data_min_date'] = min_date
else:
    st.error("âŒ ç„¡æ³•æŠ“å–æ¨™çš„è³‡æ–™ï¼Œè«‹ç¢ºèªä»£è™Ÿæ­£ç¢ºæˆ–ç¶²è·¯é€£ç·šã€‚")
    st.stop()

# ===============================================================
# å€å¡Š 2: æ—¥æœŸé¸æ“‡èˆ‡æŒ‰éˆ•æ§åˆ¶ (Bug Fix é‡é»å€)
# ===============================================================

# 1. åˆå§‹åŒ– session_state
if 'start_date' not in st.session_state:
    st.session_state['start_date'] = pd.to_datetime("2015-01-01").date()
if 'end_date' not in st.session_state:
    st.session_state['end_date'] = pd.to_datetime("today").date()

# --- [é—œéµä¿®å¾©] å¼·åˆ¶æ ¡æ­£æ—¥æœŸç¯„åœï¼Œé˜²æ­¢å ±éŒ¯ ---
# ç¢ºä¿ start_date ä¸æ—©æ–¼ min_date
if st.session_state['start_date'] < min_date:
    st.session_state['start_date'] = min_date

# ç¢ºä¿ end_date ä¸æ—©æ–¼ min_date (é˜²æ­¢åˆ‡æ›åˆ°æ–°ä¸Šå¸‚è‚¡ç¥¨æ™‚å‡ºéŒ¯)
if st.session_state['end_date'] < min_date:
    st.session_state['end_date'] = min_date

# ç¢ºä¿ end_date ä¸æ™šæ–¼ max_date
if st.session_state['end_date'] > max_date:
    st.session_state['end_date'] = max_date

# ç¢ºä¿ start_date ä¸æ™šæ–¼ end_date (é‚è¼¯ä¿è­·)
if st.session_state['start_date'] > st.session_state['end_date']:
    st.session_state['start_date'] = min_date
# ---------------------------------------------

# 2. å®šç¾©æ›´æ–°æ—¥æœŸçš„ Callback
def update_dates(years=None, is_all=False):
    today = pd.to_datetime("today").date()
    # é™åˆ¶çµæŸæ—¥æœŸä¸è¶…éè³‡æ–™æ¥µé™
    effective_end = min(today, max_date) if max_date else today
    st.session_state['end_date'] = effective_end
    
    if is_all:
        available_min = st.session_state.get('data_min_date', min_date)
        st.session_state['start_date'] = available_min
    elif years:
        target_start = effective_end - pd.DateOffset(years=years)
        final_start = max(target_start.date(), min_date) if min_date else target_start.date()
        st.session_state['start_date'] = final_start

# 3. é¡¯ç¤ºå¿«é€ŸæŒ‰éˆ•
st.subheader("ğŸ› ï¸ åƒæ•¸è¨­å®š")
btn_col1, btn_col2, btn_col3, btn_col4, btn_col5 = st.columns(5)

with btn_col1: st.button("ä¸€å¹´", on_click=update_dates, kwargs={'years': 1}, use_container_width=True)
with btn_col2: st.button("ä¸‰å¹´", on_click=update_dates, kwargs={'years': 3}, use_container_width=True)
with btn_col3: st.button("äº”å¹´", on_click=update_dates, kwargs={'years': 5}, use_container_width=True)
with btn_col4: st.button("åå¹´", on_click=update_dates, kwargs={'years': 10}, use_container_width=True)
with btn_col5: st.button("å…¨éƒ½è¦", on_click=update_dates, kwargs={'is_all': True}, use_container_width=True)

st.caption(f"ğŸ“… ç›®å‰è¨­å®šåˆ†æå€é–“ï¼š{st.session_state['start_date']} â€” {st.session_state['end_date']}")

# 4. è¡¨å–®èˆ‡åŸ·è¡ŒæŒ‰éˆ•
with st.form("param_form"):
    c1, c2, c3 = st.columns(3)
    with c1:
        # é€™è£¡æœƒè®€å–å·²ç¶“ã€Œæ ¡æ­£ã€éçš„ session_stateï¼Œæ‰€ä»¥ä¸æœƒå´©æ½°
        start_date = st.date_input("é–‹å§‹æ—¥æœŸ", key="start_date", min_value=min_date, max_value=max_date)
    with c2:
        end_date = st.date_input("çµæŸæ—¥æœŸ", key="end_date", min_value=min_date, max_value=max_date)
    with c3:
        sma_window = st.number_input("SMA å‡ç·šé€±æœŸ (æ—¥)", min_value=10, max_value=500, value=200, step=10)
    
    submitted = st.form_submit_button("ğŸš€ é–‹å§‹é‡åŒ–å›æ¸¬", use_container_width=True)

# ===============================================================
# è³‡æ–™è™•ç†èˆ‡åˆ†ææ ¸å¿ƒ
# ===============================================================
@st.cache_data
def load_analysis_data(start, end, p_sym, l_sym):
    tickers = [p_sym, l_sym]
    try:
        raw = yf.download(tickers, start=start, end=end, auto_adjust=False, progress=False)
    except Exception:
        return None

    if raw.empty: return None

    df = pd.DataFrame()
    target_col = "Adj Close" if "Adj Close" in str(raw.columns) else "Close"
    
    try:
        if isinstance(raw.columns, pd.MultiIndex):
            if "Adj Close" in raw.columns.levels[0]:
                df = raw["Adj Close"].copy()
            elif "Close" in raw.columns.levels[0]:
                df = raw["Close"].copy()
            else:
                df = raw.xs(target_col, axis=1, level=0, drop_level=True)
        else:
            df = raw[[target_col]] if target_col in raw.columns else raw
    except:
        return None

    cols_map = {}
    for col in df.columns:
        col_str = str(col)
        clean_p = p_sym.replace(".TW", "")
        clean_l = l_sym.replace(".TW", "")
        
        if clean_p in col_str: cols_map[col] = "Base"
        elif clean_l in col_str: cols_map[col] = "Lev"
    
    df = df.rename(columns=cols_map)
    df = df.dropna()
    
    if "Base" not in df.columns or "Lev" not in df.columns:
        return None
        
    return df

if submitted:
    with st.spinner(f"æ­£åœ¨è¨ˆç®— {selected_proto_name} vs {selected_lev_name} ..."):
        price = load_analysis_data(start_date, end_date, proto_symbol, lev_symbol)
        
        if price is None or price.empty:
            st.error("âŒ ç„¡æ³•ä¸‹è¼‰è³‡æ–™æˆ–è³‡æ–™ä¸è¶³ï¼Œè«‹æª¢æŸ¥æ—¥æœŸå€é–“ã€‚")
        else:
            base_label = selected_proto_name.split(" ")[2]
            lev_label = selected_lev_name.split(" ")[0]

            # 1. æŒ‡æ¨™è¨ˆç®—
            price["SMA_Base"] = price["Base"].rolling(sma_window).mean()
            price["SMA_Lev"]  = price["Lev"].rolling(sma_window).mean()
            price["Gap_Base"] = (price["Base"] - price["SMA_Base"]) / price["SMA_Base"]
            price["Gap_Lev"]  = (price["Lev"] - price["SMA_Lev"]) / price["SMA_Lev"]

            df = price.dropna().copy()
            
            st.success(f"âœ… åˆ†æå®Œæˆï¼ æ•¸æ“šå€é–“: {df.index.min().date()} ~ {df.index.max().date()} (å…± {len(df)} äº¤æ˜“æ—¥)")

            # PART A: SMA Gap
            st.subheader(f"ğŸ“‰ SMA Gap ä¹–é›¢ç‡åˆ†ä½ˆåœ– ({base_label} vs {lev_label})")
            fig_gap = go.Figure()
            fig_gap.add_trace(go.Scatter(x=df.index, y=df["Gap_Base"], name=f"{base_label} Gap%", line=dict(color='blue', width=1.5)))
            fig_gap.add_trace(go.Scatter(x=df.index, y=df["Gap_Lev"], name=f"{lev_label} Gap%", line=dict(color='red', width=1.5)))
            fig_gap.add_hline(y=0, line_dash="dash", line_color="black", opacity=0.5)
            fig_gap.update_layout(title=f"èˆ‡ {sma_window}SMA çš„ä¹–é›¢ç¨‹åº¦æ¯”è¼ƒ", yaxis_tickformat=".1%", hovermode="x unified", height=400)
            st.plotly_chart(fig_gap, use_container_width=True)

            # PART B: åƒ¹æ ¼èµ°å‹¢
            st.subheader(f"ğŸ“ˆ åƒ¹æ ¼èµ°å‹¢å°ç…§")
            fig_price = make_subplots(specs=[[{"secondary_y": True}]])
            fig_price.add_trace(go.Scatter(x=df.index, y=df["Base"], name=f"{base_label} æ”¶ç›¤åƒ¹", line=dict(color='rgba(0,0,255,0.5)', width=1)), secondary_y=False)
            fig_price.add_trace(go.Scatter(x=df.index, y=df["SMA_Base"], name=f"{base_label} SMA", line=dict(color='blue', width=2)), secondary_y=False)
            fig_price.add_trace(go.Scatter(x=df.index, y=df["Lev"], name=f"{lev_label} æ”¶ç›¤åƒ¹", line=dict(color='rgba(255,0,0,0.5)', width=1)), secondary_y=True)
            fig_price.add_trace(go.Scatter(x=df.index, y=df["SMA_Lev"], name=f"{lev_label} SMA", line=dict(color='red', width=2)), secondary_y=True)
            fig_price.update_layout(title_text=f"å·¦è»¸: {base_label} / å³è»¸: {lev_label}", hovermode="x unified", height=500)
            st.plotly_chart(fig_price, use_container_width=True)

            # PART C: ç©¿è¶Šçµ±è¨ˆ
            st.subheader("â±ï¸ ç©¿è¶Šå»¶é²æ™‚é–“çµ±è¨ˆ (Time Lag Analysis)")
            bull_Base = df["Base"] > df["SMA_Base"]
            bull_Lev  = df["Lev"] > df["SMA_Lev"]

            cross_up_Base = df[(bull_Base) & (~bull_Base.shift(1).fillna(True))].index
            cross_up_Lev  = df[(bull_Lev) & (~bull_Lev.shift(1).fillna(True))].index
            cross_dn_Base = df[(~bull_Base) & (bull_Base.shift(1).fillna(False))].index
            cross_dn_Lev  = df[(~bull_Lev) & (bull_Lev.shift(1).fillna(False))].index

            def calc_lag_stats(base_dates, target_dates):
                lags = []
                for d in base_dates:
                    candidates = [t for t in target_dates if abs((t - d).days) <= 60]
                    if candidates:
                        nearest = min(candidates, key=lambda x: abs((x - d).days))
                        diff = (nearest - d).days
                        lags.append(diff)
                if not lags: return 0, 0
                return np.mean(lags), len(lags)

            lag_up_val, count_up = calc_lag_stats(cross_up_Base, cross_up_Lev)
            lag_dn_val, count_dn = calc_lag_stats(cross_dn_Base, cross_dn_Lev)

            c_stat1, c_stat2 = st.columns(2)
            with c_stat1:
                st.markdown("### ğŸ”» ä¸‹è·Œè¶¨å‹¢ (è·Œç ´ SMA)")
                if lag_dn_val < 0: status = f"âš¡ {lev_label} ææ—© {abs(lag_dn_val):.1f} å¤©"
                else: status = f"ğŸ¢ {lev_label} å»¶é² {lag_dn_val:.1f} å¤©"
                st.info(f"**çµ±è¨ˆ {count_dn} æ¬¡äº‹ä»¶:**\n### {status}")

            with c_stat2:
                st.markdown("### ğŸš€ ä¸Šæ¼²è¶¨å‹¢ (çªç ´ SMA)")
                if lag_up_val > 0:
                    status = f"ğŸ¢ {lev_label} å»¶é² {lag_up_val:.1f} å¤©"
                    color = "orange"
                else:
                    status = f"âš¡ {lev_label} ææ—© {abs(lag_up_val):.1f} å¤©"
                    color = "blue"
                st.warning(f"**çµ±è¨ˆ {count_up} æ¬¡äº‹ä»¶:**\n### {status}")

            st.table(pd.DataFrame({
                "äº‹ä»¶": [f"{lev_label} è·Œç ´", f"{lev_label} çªç ´"],
                "åŸºæº–": [f"{base_label} è·Œç ´æ™‚", f"{base_label} çªç ´æ™‚"],
                "å¹³å‡æ™‚å·®": [f"{lag_dn_val:.1f} å¤©", f"{lag_up_val:.1f} å¤©"]
            }))

else:
    st.info("ğŸ‘† è«‹é¸æ“‡ä¸Šæ–¹æ¨™çš„èˆ‡åƒæ•¸ï¼Œä¸¦é»æ“Šã€ŒğŸš€ é–‹å§‹é‡åŒ–å›æ¸¬ã€")
