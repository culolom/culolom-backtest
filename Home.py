"""
HamrLab Backtest Platform main entry.
Main page: Dashboard style layout with Password Protection & Market Signals.
"""

import streamlit as st
import os
import datetime
import pandas as pd
import glob
import auth  # å¼•å…¥æœƒå“¡é©—è­‰æ¨¡çµ„

# 1. é é¢è¨­å®š
st.set_page_config(
    page_title="å€‰é¼ é‡åŒ–æˆ°æƒ…å®¤ | ç™½éŠ€å°å€‰é¼ å°ˆå±¬ç¦åˆ©",
    page_icon="ğŸ¹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ------------------------------------------------------
# ğŸ”’ æœƒå“¡é©—è­‰å®ˆé–€å“¡
# ------------------------------------------------------
if not auth.check_password():
    st.stop()

# ------------------------------------------------------
# âœ… å…¨åŸŸé…ç½®èˆ‡å·¥å…·å‡½å¼
# ------------------------------------------------------
DATA_DIR = "data"

# ======================================
# ğŸ”§ æ›´æ–°å¾Œçš„å‹•èƒ½æ’è¡Œæ¦œæ¨™çš„æ¸…å–®
# ======================================
TARGET_SYMBOLS = [
    "0050.TW", "2330.TW", "00878.TW", "00662.TW", "00646.TW", 
    "00670L.TW", "00647L.TW", "006208.TW", "00631L.TW", "00663L.TW", 
    "00675L.TW", "00685L.TW", "00708L.TW", "00635U.TW", 
    "QQQ", "QLD", "TQQQ", "SPY", "BTC-USD"
]

def find_csv_for_symbol(symbol: str, files: list):
    symbol_lower = symbol.lower()
    for f in files:
        name = os.path.basename(f).lower()
        if symbol_lower in name:
            return f
    return None

def load_price_series(csv_path: str):
    try:
        df = pd.read_csv(csv_path)
        df.iloc[:, 0] = pd.to_datetime(df.iloc[:, 0], errors="coerce")
        df = df.set_index(df.columns[0]).sort_index()
        candidates = ["Adj Close", "Close", "close", "adjclose"]
        for c in candidates:
            if c in df.columns:
                return df[c].astype(float).dropna()
        num_cols = df.select_dtypes(include="number").columns
        return df[num_cols[-1]].astype(float).dropna() if len(num_cols) > 0 else None
    except Exception:
        return None

def classify_trend(price: pd.Series):
    if price is None or len(price) < 200:
        return "è³‡æ–™ä¸è¶³", "â¬œ"
    ma200 = price.rolling(200).mean().iloc[-1]
    last = price.iloc[-1]
    if pd.isna(ma200) or pd.isna(last):
        return "è³‡æ–™ä¸è¶³", "â¬œ"
    diff = (last / ma200) - 1.0
    if diff > 0.05: return "å¤šé ­", "ğŸŸ¢"
    elif diff > 0: return "åå¤š", "ğŸŸ¡"
    elif diff > -0.05: return "åç©º", "ğŸŸ "
    else: return "ç©ºé ­", "ğŸ”´"

def get_momentum_ranking(data_dir="data", symbols=None):
    if not os.path.exists(data_dir):
        return None, "ç„¡è³‡æ–™å¤¾"
    today = pd.Timestamp.today()
    this_month_start = today.replace(day=1)
    end_date = this_month_start - pd.Timedelta(days=1)
    start_date = end_date - pd.DateOffset(months=12)
    results = []
    all_files = [f for f in os.listdir(data_dir) if f.endswith(".csv")]

    if symbols:
        use_files = []
        for s in symbols:
            matched = find_csv_for_symbol(s, all_files)
            if matched: use_files.append(os.path.basename(matched))
    else:
        use_files = all_files

    for f in use_files:
        symbol = f.replace(".csv", "")
        try:
            df = pd.read_csv(os.path.join(data_dir, f))
            col_price = "Adj Close" if "Adj Close" in df.columns else "Close"
            df["Date"] = pd.to_datetime(df["Date"])
            df = df.set_index("Date").sort_index()
            df["MA_200"] = df[col_price].rolling(window=200).mean()
            hist_window = df.loc[:end_date]
            if hist_window.empty: continue
            last_valid = hist_window.index[-1]
            p_end = hist_window[col_price].iloc[-1]
            ma_end = df.loc[last_valid, "MA_200"]
            start_window = df.loc[:start_date]
            if start_window.empty: continue
            p_start = start_window[col_price].iloc[-1]
            ret = (p_end - p_start) / p_start
            results.append({"ä»£è™Ÿ": symbol, "12æœˆç´¯ç©å ±é…¬": ret * 100, "æ”¶ç›¤åƒ¹": p_end, "200SMA": ma_end})
        except Exception:
            continue
    if not results: return None, end_date
    df_res = pd.DataFrame(results).sort_values("12æœˆç´¯ç©å ±é…¬", ascending=False).reset_index(drop=True)
    df_res.index += 1
    return df_res, end_date

# ------------------------------------------------------
# 2. å´é‚Šæ¬„
# ------------------------------------------------------
with st.sidebar:
    if os.path.exists("logo.png"): st.image("logo.png", width=120)
    else: st.title("ğŸ¹") 
    st.title("å€‰é¼ é‡åŒ–æˆ°æƒ…å®¤")
    st.caption("v1.2.0 | ç™½éŠ€å°å€‰é¼ é™å®š")
    st.divider()
    st.markdown("### ğŸ”— å¿«é€Ÿé€£çµ")
    st.page_link("https://hamr-lab.com/", label="éƒ¨è½æ ¼é¦–é ", icon="ğŸ ")
    st.page_link("https://www.youtube.com/@hamr-lab", label="YouTube é »é“", icon="ğŸ“º")
    st.page_link("https://hamr-lab.com/contact", label="å•é¡Œå›å ± / è¨±é¡˜", icon="ğŸ“")
    st.divider()
    if st.button("ğŸšª ç™»å‡ºç³»çµ±"):
        st.session_state["password_correct"] = False
        st.rerun()

# ------------------------------------------------------
# 3. ä¸»ç•«é¢
# ------------------------------------------------------
st.title("ğŸš€ æˆ°æƒ…å®¤è»ç«åº«")

# ç‹€æ…‹æª¢æŸ¥
files = glob.glob(os.path.join(DATA_DIR, "*.csv"))
last_update = datetime.datetime.fromtimestamp(os.path.getmtime(max(files, key=os.path.getmtime))).strftime("%Y-%m-%d") if files else "N/A"
st.caption(f"âœ… ç³»çµ±æ•¸æ“šæ­£å¸¸ | ğŸ“… æœ€å¾Œæ›´æ–°ï¼š{last_update}")

st.markdown("""
æ­¡è¿ä¾†åˆ° **å€‰é¼ é‡åŒ–æˆ°æƒ…å®¤**ï¼ä¸‹æ–¹ç‚ºç™½éŠ€å°å€‰é¼ å°ˆå±¬çš„ç­–ç•¥å¯¦é©—å®¤èˆ‡å¸‚å ´å„€è¡¨æ¿ã€‚
åˆ©ç”¨ **200æ—¥å‡ç·šè¶¨å‹¢éæ¿¾** èˆ‡ **å‹•èƒ½æ’è¡Œ**ï¼Œåœ¨ç‰›å¸‚é€²æ”»ã€ç†Šå¸‚é˜²å®ˆã€‚
""")

st.divider()

# ==========================================
# ğŸ› ï¸ ç­–ç•¥å¯¦é©—å®¤ (è‡ªå‹•æƒæ + ç¾åŒ–)
# ==========================================
st.subheader("ğŸ› ï¸ é¸æ“‡ä½ çš„å¯¦é©—ç­–ç•¥")

HIDE_STRATEGIES = ["temp_test", "old_strategy"]

META_INFO = {
    "1_QQQLRS": {
        "name": "QQQ LRS å‹•æ…‹æ§“æ¡¿",
        "icon": "ğŸ¦…",
        "tags": ["ç¾è‚¡", "Nasdaq", "å‹•æ…‹æ§“æ¡¿"],
        "desc": "ä»¥ QQQ 200SMA ç‚ºè¨Šè™Ÿï¼Œå‹•æ…‹åˆ‡æ› QLD (2x) æˆ– TQQQ (3x)ï¼Œæ•æ‰ç§‘æŠ€è‚¡é•·æœŸä¸Šå‡è¶¨å‹¢ã€‚"
    },
    "2_0050LRS": {
        "name": "0050 LRS å‹•æ…‹æ§“æ¡¿",
        "icon": "ğŸ‡¹ğŸ‡¼",
        "tags": ["å°è‚¡", "0050", "æ›éšªèª¿æ•´"],
        "desc": "ä»¥å°è‚¡å¤§ç›¤ç‚ºè¨Šè™Ÿæºï¼Œå‹•æ…‹èª¿æ•´æ­£2æ§“æ¡¿æ¯”ä¾‹ï¼Œè¿½æ±‚æ›´å„ªåŒ–çš„é¢¨éšªå›å ±æ¯”ã€‚"
    },
    "3_Basic0050score": {
        "name": "0050 æ™¯æ°£ç‡ˆè™Ÿ (åŸºç¤)",
        "icon": "ğŸš¦",
        "tags": ["åŸºæœ¬é¢", "æ™¯æ°£å¾ªç’°"],
        "desc": "åœ‹ç™¼æœƒæ™¯æ°£å°ç­–ä¿¡è™Ÿç°¡å–®ç­–ç•¥ï¼šè—ç‡ˆè²·é€²ã€ç´…ç‡ˆè³£å‡ºã€‚"
    },
    "7_50dbdl": {
        "name": "å–®ä¸€æ¨™çš„é›™å‘ä¹–é›¢ç­–ç•¥",
        "icon": "âš–ï¸",
        "tags": ["å‹•æ…‹å®šæœŸå®šé¡", "æŠ„åº•å¥—åˆ©", "å–®ä¸€æ¨™çš„"],
        "desc": "æœ€æ–°ç‰ˆæœ¬ï¼æ”¯æ´ SMA è¶¨å‹¢éæ¿¾é–‹é—œï¼Œé€éè² ä¹–é›¢ DCA åŠ ç¢¼èˆ‡é«˜ä½å¥—åˆ©æ¸›ç¢¼ï¼Œå¤§å¹…å„ªåŒ–æ­£2é•·æœŸæŒæœ‰çš„å¿ƒç†å£“åŠ›ã€‚"
    },
    "8_nsf": {
        "name": "0050 åœ‹å®‰åŸºé‡‘çˆ†æ“Šæ³•",
        "icon": "ğŸ›¡ï¸",
        "tags": ["æ”¿ç­–ç›¤", "æŠ„åº•çˆ†æ“Š"],
        "desc": "æ¨¡æ“¬åœ‹å®‰åŸºé‡‘é€²å ´å¿ƒç†ï¼Œåœ¨æ¥µç«¯ææ…Œæ™‚å‹‡æ•¢æ‰“å‡ºçˆ†æ“Šéƒ¨ä½ã€‚"
    }
}

pages_dir = "pages"
page_files = sorted(glob.glob(os.path.join(pages_dir, "*.py")))
cols = st.columns(2)
count = 0

for file_path in page_files:
    filename = os.path.basename(file_path).replace(".py", "")
    if filename in HIDE_STRATEGIES: continue
    
    info = META_INFO.get(filename, {
        "name": filename, "icon": "ğŸ“„", "tags": ["New"], "desc": "ç­–ç•¥æè¿°è£œå……ä¸­..."
    })
    
    with cols[count % 2]:
        with st.container(border=True):
            st.markdown(f"### {info['icon']} {info['name']}")
            st.markdown(" ".join([f"`{tag}`" for tag in info['tags']]))
            st.write(info['desc'])
            st.page_link(file_path, label="é€²å…¥ç­–ç•¥å›æ¸¬", icon="ğŸ‘‰", use_container_width=True)
    count += 1

st.divider()

# ==========================================
# ğŸ“Š å¸‚å ´å„€è¡¨æ¿
# ==========================================
st.subheader("ğŸ“Œ é‡é»å¸‚å ´è¶¨å‹¢ (SMA200)")
summary_cols = st.columns(4)
ASSETS = [
    {"label": "ç¾è‚¡ç§‘æŠ€ (QQQ)", "symbol": "QQQ"},
    {"label": "å°è‚¡å¤§ç›¤ (0050)", "symbol": "0050.TW"},
    {"label": "æ¯”ç‰¹å¹£ (BTC)", "symbol": "BTC-USD"},
    {"label": "å…¨çƒè‚¡å¸‚ (VT)", "symbol": "VT"},
]

for i, asset in enumerate(ASSETS):
    with summary_cols[i]:
        csv_path = find_csv_for_symbol(asset["symbol"], files)
        if csv_path:
            p = load_price_series(csv_path)
            t_text, t_icon = classify_trend(p)
            st.metric(asset["label"], t_text, t_icon)
        else:
            st.metric(asset["label"], "ç„¡è³‡æ–™", "â¬œ")

# ==========================================
# ğŸ† æœ¬æœˆå‹•èƒ½æ’è¡Œæ¦œ
# ==========================================
st.markdown("### ğŸ† æœ¬æœˆå‹•èƒ½æ’è¡Œæ¦œ (éå» 12 å€‹æœˆç¸¾æ•ˆ)")
rank_df, calc_date = get_momentum_ranking(DATA_DIR, symbols=TARGET_SYMBOLS)

if rank_df is not None:
    st.caption(f"ğŸ“… çµ±è¨ˆåŸºæº–æ—¥ï¼š**{calc_date.strftime('%Y-%m-%d')}** (ä¸Šå€‹æœˆåº•)")
    st.dataframe(
        rank_df,
        column_config={
            "12æœˆç´¯ç©å ±é…¬": st.column_config.ProgressColumn(
                "12æœˆç´¯ç©å ±é…¬", format="%.2f%%", min_value=-50, max_value=100
            ),
            "æ”¶ç›¤åƒ¹": st.column_config.NumberColumn("æ”¶ç›¤åƒ¹", format="$%.2f"),
            "200SMA": st.column_config.NumberColumn("200SMA", format="$%.2f"),
        },
        use_container_width=True,
    )

st.markdown("---")
st.caption("ğŸš§ æ›´å¤šç­–ç•¥ (MACDã€RSI) èˆ‡æƒ…ç·’æŒ‡æ¨™é–‹ç™¼ä¸­ï¼Œæ•¬è«‹æœŸå¾…ï¼")
