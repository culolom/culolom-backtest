import requests
import pandas as pd
import io
import sys
from datetime import datetime
from pathlib import Path

# -----------------------------------------------------
# è¨­å®š
# -----------------------------------------------------
DATA_DIR = Path("data")
CSV_PATH = DATA_DIR / "SCORE.csv"

# æ”¿åºœè³‡æ–™é–‹æ”¾å¹³è‡º API (æœå°‹ä»‹é¢)
SEARCH_API = "https://data.gov.tw/api/v2/rest/dataset"

def parse_taiwan_date(date_str):
    """ è§£ææ—¥æœŸ (æ°‘åœ‹/è¥¿å…ƒ) """
    s = str(date_str).strip()
    try:
        # 198401
        if len(s) == 6 and s.isdigit():
            return datetime.strptime(s, "%Y%m")
        # 07301
        elif len(s) == 5 and s.isdigit():
            year = int(s[:3]) + 1911
            month = int(s[3:])
            return datetime(year, month, 1)
        # 1984-01, 1984/01
        elif "-" in s or "/" in s:
            s = s.replace("/", "-")
            parts = s.split("-")
            if len(parts) >= 2:
                year = int(parts[0])
                month = int(parts[1])
                if year < 1911: year += 1911
                return datetime(year, month, 1)
    except:
        pass
    return None

def fetch_score_data():
    print("ğŸš€ [Job: Score] é–‹å§‹åŸ·è¡Œï¼šä½¿ç”¨ API æœå°‹æ™¯æ°£å°ç­–ä¿¡è™Ÿ...")
    DATA_DIR.mkdir(parents=True, exist_ok=True)

    csv_url = None
    target_title = ""

    # 1. æœå°‹è³‡æ–™é›†
    # é—œéµå­—è¨­ç‚º "æ™¯æ°£å°ç­–ä¿¡è™Ÿ"ï¼Œé€™æ¨£æœ€æº–
    print("   ...æ­£åœ¨å‘¼å«æœå°‹ API...")
    try:
        # q=é—œéµå­—
        res = requests.get(SEARCH_API, params={"q": "æ™¯æ°£å°ç­–ä¿¡è™Ÿ"}, timeout=30)
        res.raise_for_status()
        data = res.json()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æœå°‹çµæœ
        if not data.get("success"):
            print(f"âŒ API å‘¼å«å¤±æ•—: {data}")
            sys.exit(1)
            
        datasets = data.get("result", {}).get("records", [])
        if not datasets:
            print("âŒ æœå°‹ä¸åˆ°ä»»ä½•è³‡æ–™é›†")
            sys.exit(1)
            
        print(f"   ...æ‰¾åˆ° {len(datasets)} å€‹è³‡æ–™é›†ï¼Œé–‹å§‹ç¯©é¸ CSV...")

        # 2. éæ­·è³‡æ–™é›†å°‹æ‰¾ CSV
        for ds in datasets:
            # å–å¾—è³‡æ–™é›† ID
            ds_id = ds.get("id")
            ds_title = ds.get("title", "")
            
            # å‘¼å«è©³æƒ… API å–å¾—è³‡æºåˆ—è¡¨
            detail_res = requests.get(f"{SEARCH_API}/{ds_id}", timeout=10)
            if detail_res.status_code != 200:
                continue
                
            resources = detail_res.json().get("result", {}).get("resources", [])
            
            for r in resources:
                fmt = str(r.get("file_ext") or r.get("format") or "").lower()
                desc = str(r.get("resource_description") or "")
                
                # åˆ¤å®šæ˜¯å¦ç‚º CSV
                if "csv" in fmt or "csv" in desc.lower():
                    csv_url = r.get("resource_url")
                    target_title = ds_title
                    print(f"   âœ… é–å®šè³‡æ–™é›†: {ds_title}")
                    print(f"   â¬‡ï¸ æ‰¾åˆ° CSV è³‡æº: {csv_url}")
                    break
            
            if csv_url: break
            
    except Exception as e:
        print(f"âŒ API æœå°‹éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
        sys.exit(1)

    if not csv_url:
        print("âŒ æ‰€æœ‰æœå°‹çµæœä¸­éƒ½æ²’æœ‰ç™¼ç¾ CSV æ ¼å¼çš„æª”æ¡ˆ")
        sys.exit(1)

    # 3. ä¸‹è¼‰èˆ‡è™•ç†
    try:
        print(f"   ...é–‹å§‹ä¸‹è¼‰...")
        file_res = requests.get(csv_url, timeout=60)
        file_res.raise_for_status()
        
        # è§£ç¢¼
        content = file_res.content
        try:
            df_raw = pd.read_csv(io.BytesIO(content), encoding='utf-8')
        except:
            df_raw = pd.read_csv(io.BytesIO(content), encoding='big5')
            
        print(f"   ...è§£æä¸­ (åŸå§‹å¤§å° {df_raw.shape})...")
        
        records = []
        # æš´åŠ›æƒææ¬„ä½æŠ“å– æ—¥æœŸ & åˆ†æ•¸
        for idx, row in df_raw.iterrows():
            date_val = None
            score_val = None
            
            for col in df_raw.columns:
                val = str(row[col]).strip()
                
                # æŠ“æ—¥æœŸ
                if date_val is None:
                    dt = parse_taiwan_date(val)
                    if dt: 
                        date_val = dt
                        continue
                
                # æŠ“åˆ†æ•¸ (æ’é™¤æ—¥æœŸæ•¸å­—)
                if score_val is None:
                    clean_val = val.replace('.', '', 1)
                    if clean_val.isdigit():
                        v = float(val)
                        if 9 <= v <= 55: # åˆç†åˆ†æ•¸ç¯„åœ
                            score_val = v
            
            if date_val and score_val:
                records.append({
                    "Date": date_val.strftime("%Y-%m-%d"),
                    "Score": score_val
                })

        if not records:
            print("âŒ è§£æå¾Œç„¡è³‡æ–™ï¼Œç„¡æ³•è­˜åˆ¥æ—¥æœŸèˆ‡åˆ†æ•¸æ¬„ä½")
            print("DEBUG: å‰å¹¾è¡Œè³‡æ–™:", df_raw.head())
            sys.exit(1)

        # 5. å­˜æª”
        df = pd.DataFrame(records)
        df = df.drop_duplicates(subset=["Date"], keep="last")
        df = df.set_index("Date").sort_index()
        
        df.to_csv(CSV_PATH)
        print(f"ğŸ‰ [Job: Score] æˆåŠŸï¼å·²å„²å­˜ {len(df)} ç­†è³‡æ–™è‡³: {CSV_PATH}")
        print(f"   æœ€æ–°æ•¸æ“š: {df.index[-1]} -> {df['Score'].iloc[-1]} åˆ†")

    except Exception as e:
        print(f"âŒ ä¸‹è¼‰æˆ–è§£æå¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    fetch_score_data()
